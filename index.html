<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CoBra</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">CoBra: Complementary Branch Fusing Class and Semantic Knowledge for Robust Weakly Supervised Semantic Segmentation</h1>
          <div class="is-size-5 publication-authors">

            <span class="author-block">
              <a>Anonymous 9555</a>
            </span>
          </div>

  

          <div class="column has-text-centered">
            <div class="publication-links">
   
              <span class="link-block">
                <a href="https://github.com/anno9555"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/main1.png" alt="main" height="100%">
      <h2 class="subtitle has-text-centered">
        Overview illustration of our model, Cross Complementary Branch (<b>CoBra</b>).
        The dual branch framework consists of the Class-Aware Knowledge branch with CNN (top) and the Semantic-Aware Knowledge branch with ViT (bottom).
        The input image is passed down to both branches.
        <b>Class-Aware Knowledge (CAK) Branch</b>: The CNN outputs a feature map which generates (1) CNN CAMs, (2) Pseudo-Labels from CNN CAMs, and (3) Class-Aware Projection (CAP).
        <b>Semantic-Aware Knowledge (SAK) Branch</b>: The ViT outputs Patch Embeddings which generate (1) ViT CAMs, (2) Semantic-Aware Projection (SAP) and (3) Patch Affinity.
        <b>Complementary Branch Losses</b>: Once the necessary outputs are prepared, we employ various losses: (1) class loss: The typical classification loss based on the individual classification predictions of each CNN CAM and ViT CAM. (2) cam loss: The L1 loss between the CNN CAM and ViT CAM. (3) SAP Loss: The class-aware knowledge from the pseudo labels guides SAP to identify more accurate class-specific patches. (4) CAP Loss: The semantic-aware knowledge from the patch affinity improves the semantic sensitivity of ViT CAM.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Leveraging semantically precise pseudo masks derived from image-level class knowledge for segmentation, namely image-level Weakly Supervised Semantic Segmentation (WSSS), still remains challenging. While Class Activation Maps (CAMs) using CNNs have steadily been contributing to the success of WSSS, the resulting activation maps often narrowly focus on class-specific parts (e.g., only face of human). On the other hand, recent works based on vision transformers (ViT) have shown promising results based on their self-attention mechanism to capture the semantic parts \textcolor{red}{(e.g., entire body parts of human with a dog nearby).} In this work, we propose \textbf{Co}mplementary \textbf{Bra}nch (\textbf{CoBra}), a novel dual branch framework consisting of two distinct architectures which provide valuable complementary knowledge of class (from CNN) and semantic (from ViT) to each branch. In particular, we learn Class-Aware Projection (CAP) for the CNN branch and Semantic-Aware Projection (SAP) for the ViT branch to explicitly fuse their complementary knowledge and facilitate a new type of extra patch-level supervision.
    Our model, through <b>CoBra</b>, fuses CNN and ViT's complementary outputs to create robust pseudo masks that integrate both class and semantic information effectively. Extensive experiments qualitatively and quantitatively investigate how CNN and ViT complement each other on the PASCAL VOC 2012 dataset, showing a state-of-the-art WSSS result. This includes not only the masks generated by our model, but also the segmentation results derived from utilizing these masks as pseudo labels. 
        </div>
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/jNQXAC9IVRw?si=K-u3llTqxptv-xLm"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>

      </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3 has-text-centered">Method</h3>
        
        <div class="content has-text-centered">
          <img src="./static/images/main4.png" alt="Main figure">
        </div>
        <div class="content has-text-justified">
          <p>
            The pipeline of EAGLE. 
            Leveraging the Laplacian matrix, which integrates hierarchically projected image key features and color affinity, the model harnesses eigenvector clustering to capture an object-centric perspective.
             Our model further adopts an object-level contrastive loss, utilizing the projected vector Z and  ̃Z. 
             The learnable prototype Φ, acts as a singular anchor that contrasts positive objects and negative objects. 
             Our object-level contrastive loss is computed in two distinct manners: crosswise and non-crosswise to ensure semantic consistency.
          </p>
        </div>
      </div>
    </div>
    
  </div>
</section>

<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
